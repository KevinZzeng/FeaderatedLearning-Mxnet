{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit000112c82aae46049a43b9e45b233c07",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试梯度更新算法可行性\n",
    "以及for循环遍历神经网络层可行性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import autograd as ag\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet.gluon import loss \n",
    "\n",
    "def LeNet_(activation='relu'):\n",
    "    # 获取一个结构定义完整的LeNet卷积神经网络\n",
    "    # 激活函数可自选 默认为sigmoid\n",
    "    net = nn.Sequential()\n",
    "    net.add(nn.Conv2D(channels=6, kernel_size=(5,5), activation=activation),\n",
    "            nn.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "            nn.Conv2D(channels=16, kernel_size=(5,5), activation=activation),\n",
    "            nn.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "            # Dense会默认将(批量大小， 通道， 高， 宽)形状的输入转换成\n",
    "            # (批量大小， 通道 * 高 * 宽)形状的输入\n",
    "            nn.Dense(120, activation=activation),\n",
    "            nn.Dense(84, activation=activation),\n",
    "            nn.Dense(10))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "net = LeNet_()\n",
    "input_shape = (1,1,28,28)\n",
    "ctx = [mx.gpu()]\n",
    "mx.random.seed(42)\n",
    "net.initialize(mx.init.Xavier(magnitude=2.24),ctx=ctx)\n",
    "_ = net(nd.random.uniform(shape=input_shape,ctx=ctx[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "验证集准确率 validation acc:accuracy=0.100000\n"
    }
   ],
   "source": [
    "#验证\n",
    "#val_x,val_y = val_data_set[0],val_data_set[1]\n",
    "#val_data = mx.io.NDArrayIter(val_x,val_y,batch_size=100)\n",
    "mnist = mx.test_utils.get_mnist()\n",
    "val_data = mx.io.NDArrayIter(mnist['test_data'],mnist['test_label'],batch_size=100)    \n",
    "for batch in val_data:\n",
    "    data = gluon.utils.split_and_load(batch.data[0],ctx_list=ctx,batch_axis=0)\n",
    "    label = gluon.utils.split_and_load(batch.label[0],ctx_list=ctx,batch_axis=0)\n",
    "    outputs = []\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for x in data:\n",
    "        outputs.append(net(x))\n",
    "    metric.update(label,outputs)\n",
    "print('验证集准确率 validation acc:%s=%f'%metric.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_gradient(net,local_gradient=[]):\n",
    "    local_gradient['weight'].clear()\n",
    "    local_gradient['bias'].clear()\n",
    "    for layer in net:\n",
    "        try:\n",
    "            shape_w = layer.weight.data().shape\n",
    "            shape_b = layer.bias.data().shape\n",
    "        except:\n",
    "            continue\n",
    "        local_gradient['weight'].append(nd.zeros(shape=shape_w,ctx=ctx[0]))\n",
    "        local_gradient['bias'].append(nd.zeros(shape=shape_b,ctx=ctx[0]))\n",
    "    \n",
    "def collect_gradient(net, local_gradient,batch_size):\n",
    "    idx = 0\n",
    "    for layer in net:\n",
    "        try:\n",
    "            grad_w = layer.weight.data().grad\n",
    "            grad_b = layer.bias.data().grad\n",
    "        except:\n",
    "            continue\n",
    "        local_gradient['weight'][idx] = local_gradient['weight'][idx] + grad_w.as_in_context(local_gradient['weight'][idx].context)/batch_size\n",
    "        local_gradient['bias'][idx] = local_gradient['bias'][idx] + grad_b.as_in_context(local_gradient['bias'][idx].context)/batch_size\n",
    "        idx+=1\n",
    "\n",
    "def updata_gradient(net,gradient_info,learning_rate):\n",
    "    # 由Client回传的梯度信息 更新Server模型\n",
    "    idx = 0\n",
    "    grad_w = gradient_info['weight']\n",
    "    grad_b = gradient_info['bias']\n",
    "    update_flag = False\n",
    "    for layer in net:\n",
    "        try:\n",
    "            layer.weight.data()[:] = layer.weight.data()[:] - learning_rate*grad_w[idx]\n",
    "            #layer.weight.set_data(layer.weight.data()[:] - learning_rate*gradient_info[idx])\n",
    "            layer.bias.data()[:] = layer.bias.data()[:] - learning_rate*grad_b[idx]\n",
    "        except:\n",
    "            continue\n",
    "        idx += 1\n",
    "    \"\"\"\n",
    "    if update_flag:\n",
    "        print(\"-gradient successfully updated-\")\n",
    "    else:\n",
    "        print(\"-gradient failure-\")\n",
    "    \"\"\"\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#训练\n",
    "train_data = mx.io.NDArrayIter(mnist['train_data'],mnist['train_label'],batch_size=100) \n",
    "epoch = 10\n",
    "metric = mx.metric.Accuracy()\n",
    "smc_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':0.02})\n",
    "#初始化梯度\n",
    "gradient_info = {'weight':[],'bias':[]}\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "training acc at epoch 0, accuracy=0.702617\ntraining acc at epoch 1, accuracy=0.939650\ntraining acc at epoch 2, accuracy=0.959250\ntraining acc at epoch 3, accuracy=0.967967\ntraining acc at epoch 4, accuracy=0.973167\ntraining acc at epoch 5, accuracy=0.976783\ntraining acc at epoch 6, accuracy=0.979517\ntraining acc at epoch 7, accuracy=0.981517\ntraining acc at epoch 8, accuracy=0.983017\ntraining acc at epoch 9, accuracy=0.984200\n"
    }
   ],
   "source": [
    "# 正常训练\n",
    "for i in range(epoch):\n",
    "    train_data.reset()\n",
    "    for batch in train_data:\n",
    "        init_gradient(net,gradient_info)\n",
    "        data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "        label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "        outputs = []\n",
    "        with ag.record():\n",
    "            for x,y in zip(data,label):\n",
    "                z = net(x)\n",
    "                loss = smc_loss(z, y)\n",
    "                loss.backward()\n",
    "                outputs.append(z)\n",
    "        #收集梯度\n",
    "        collect_gradient(net,gradient_info,batch_size=batch.data[0].shape[0])\n",
    "        updata_gradient(net,gradient_info,learning_rate=0.02)\n",
    "        metric.update(label,outputs)\n",
    "        #trainer.step(batch.data[0].shape[0])\n",
    "    name,acc = metric.get()\n",
    "    metric.reset()\n",
    "    print('training acc at epoch %d, %s=%f'%(i,name,acc))\n",
    "    # YA DA ZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "training acc at epoch accuracy=0.702000\n"
    }
   ],
   "source": [
    "# 梯度采集 模型更新测试\n",
    "train_data.reset()\n",
    "for batch in train_data:\n",
    "    init_gradient(net,gradient_info)\n",
    "    data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "    label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "    outputs = []\n",
    "    with ag.record():\n",
    "        for x,y in zip(data,label):\n",
    "            z = net(x)\n",
    "            loss = smc_loss(z, y)\n",
    "            loss.backward()\n",
    "            outputs.append(z)\n",
    "    #收集梯度\n",
    "    collect_gradient(net,gradient_info,batch_size=batch.data[0].shape[0])\n",
    "    #updata_gradient(gradient_info,learning_rate=0.02)\n",
    "    metric.update(label,outputs)\n",
    "    trainer.step(batch.data[0].shape[0])\n",
    "\n",
    "name,acc = metric.get()\n",
    "metric.reset()\n",
    "print('training acc at epoch %s=%f'%(name,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "验证集准确率 validation acc:accuracy=0.990000\n"
    }
   ],
   "source": [
    "val_data.reset()\n",
    "for batch in val_data:\n",
    "    data = gluon.utils.split_and_load(batch.data[0],ctx_list=ctx,batch_axis=0)\n",
    "    label = gluon.utils.split_and_load(batch.label[0],ctx_list=ctx,batch_axis=0)\n",
    "    outputs = []\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for x in data:\n",
    "        outputs.append(net(x))\n",
    "    metric.update(label,outputs)\n",
    "print('验证集准确率 validation acc:%s=%f'%metric.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}