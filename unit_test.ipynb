{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 下一词预测\n",
    "# mxnet.gluon.rnn.LSTM\n",
    "import sys\n",
    "path_base = \"E:\\PythonProjects\\Mxnet_FederatedLearning\"\n",
    "sys.path.append(path_base)\n",
    "import Tools\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import autograd as ag\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet.gluon import loss as gloss, nn, rnn\n",
    "import time\n",
    "import zipfile\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return mx.gpu(0); else return mx.cpu().\"\"\"\n",
    "    try:\n",
    "        ctx = mx.gpu()\n",
    "        _ = nd.array([0], ctx=ctx)\n",
    "    except mx.base.MXNetError:\n",
    "        ctx = mx.cpu()\n",
    "    return ctx\n",
    "\n",
    "context = try_gpu()\n",
    "\n",
    "class RNNModel(gluon.Block):\n",
    "    # 循环神经网络库\n",
    "    def __init__(self, mode, vocab_size, embed_dim, hidden_dim, num_layers, dropout=0.5, **kwargs):\n",
    "        \"\"\"\n",
    "        mode: RNN网络类型\n",
    "        vocab_size: 数据集不同字符的数目\n",
    "        embed_dim: 编码器神经元数目 输入数据特征数目\n",
    "        hidden_dim: 隐藏状态特征数\n",
    "        num_layers: 循环神经网络层数\n",
    "        dropout: 随机失活\n",
    "        \n",
    "        stata shape: (隐藏层个数, 批量大小, 隐藏单元个数)\n",
    "        input shape: \n",
    "        \"\"\"\n",
    "        super(RNNModel,self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.drop = nn.Dropout(dropout)\n",
    "            self.encoder = nn.Embedding(vocab_size, embed_dim, weight_initializer=mx.init.Uniform(0.1))\n",
    "\n",
    "            if mode == 'rnn_relu':\n",
    "                self.rnn = rnn.RNN(hidden_dim, num_layers, activation='relu', dropout=dropout, input_size=embed_dim)\n",
    "            elif mode == 'rnn_tanh':\n",
    "                self.rnn = rnn.RNN(hidden_dim, num_layers, dropout=dropout, input_size=embed_dim)\n",
    "            elif mode == 'lstm':\n",
    "                self.rnn = rnn.LSTM(hidden_dim, num_layers, dropout=dropout, input_size=embed_dim)\n",
    "            elif mode == 'gru':\n",
    "                self.rnn = rnn.GRU(hidden_dim, num_layers, dropout=dropout, input_size=embed_dim)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid mode %s. Options are rnn_relu, rnn_tanh, lstm, and gru\"&mode)\n",
    "\n",
    "            self.rnn.initialize(mx.init.Xavier(),ctx=context)\n",
    "            self.decoder = nn.Dense(vocab_size, in_units=hidden_dim)\n",
    "            self.hidden_dim = hidden_dim\n",
    "    \n",
    "    def forward(self, inputs, state):\n",
    "        emb = self.drop(self.encoder(inputs))\n",
    "        output, state = self.rnn(emb, state)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output.reshape((-1, self.hidden_dim)))\n",
    "        return decoded, state\n",
    "\n",
    "    def begin_state(self, *args, **kwargs):\n",
    "        return self.rnn.begin_state(*args, **kwargs)\n",
    "    \n",
    "    def grad_clipping(self, params, theta, ctx):\n",
    "        \"\"\"Clip the gradient.\"\"\"\n",
    "        if theta is not None:\n",
    "            norm = nd.array([0], ctx)\n",
    "            for param in params:\n",
    "                norm += (param.grad ** 2).sum()\n",
    "            norm = norm.sqrt().asscalar()\n",
    "            if norm > theta:\n",
    "                for param in params:\n",
    "                    param.grad[:] *= theta / norm\n",
    "    \n",
    "    def train(self, train_data, num_epochs, num_steps, clipping_norm, pred_period):\n",
    "        #input:\n",
    "        trainer = gluon.Trainer(self.rnn.collect_params(),'sgd',{'learning_rate':lr, 'momentum':0, 'wd':0})\n",
    "        loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "        self.rnn.initialize(ctx=context, force_reinit=True, init=mx.init.Xavier())\n",
    "        for epoch in range(num_epochs):\n",
    "            L_sum = 0.0\n",
    "            start_time = time.time()\n",
    "            #数据迭代器\n",
    "            #data_iter = Tools.utils.data_iter_consecutive(corpus_indices, batch_size, num_steps, context)\n",
    "            #RNN初始状态\n",
    "            state = self.begin_state(batch_size=batch_size, ctx=context)\n",
    "            for X, Y in train_data:\n",
    "                #分离上一初始状态\n",
    "                for s in state:\n",
    "                    s.detach()\n",
    "                with ag.record():\n",
    "                    output, state = self.rnn(X, state)\n",
    "                    y = Y.T.reshape((-1,))\n",
    "                    L = loss(output, Y)\n",
    "                L.backward()\n",
    "                grads = [i.grad(context) for i in model.collect_params().values()]\n",
    "                #梯度裁剪\n",
    "                gluon.utils.clip_global_norm(grads, clipping_norm * num_steps * batch_size)\n",
    "                trainer.step(batch_size)\n",
    "                L_sum += L.asscalar() * Y.size\n",
    "                n += y.size\n",
    "            if (epoch + 1) % pred_period == 0:\n",
    "                print('epoch %d, perplexity %f, time %.2f sec' % (epoch + 1, math.exp(L_sum / n), time.time() - start_time))\n",
    "\n",
    "    \n",
    "    def predict_rnn_gluon(self, prefix, num_chars, vocab_size, ctx, idx_to_char, char_to_idx):\n",
    "        # inputs: prefix 需要预测的输入 num_chars 预测字的个数 vocab_size 语料库字符数\n",
    "        # 使用model的成员函数来初始化隐藏状态\n",
    "        state = self.rnn.begin_state(batch_size=1, ctx=ctx)\n",
    "        output = [char_to_idx[prefix[0]]]\n",
    "        for t in range(num_chars + len(prefix) - 1):\n",
    "            X = nd.array([output[-1]], ctx=ctx).reshape((1, 1))\n",
    "            (Y, state) = self.rnn(X, state)  # 前向计算不需要传入模型参数\n",
    "            if t < len(prefix) - 1:\n",
    "                output.append(char_to_idx[prefix[t + 1]])\n",
    "            else:\n",
    "                output.append(int(Y.argmax(axis=1).asscalar()))\n",
    "        return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_jay_lyrics():\n",
    "    \"\"\"Load the Jay Chou lyric data set (available in the Chinese book).\"\"\"\n",
    "    #返回 四元组\n",
    "    with zipfile.ZipFile(path_base+'/data/jaychou_lyrics.txt.zip') as zin:\n",
    "        with zin.open('jaychou_lyrics.txt') as f:\n",
    "            corpus_chars = f.read().decode('utf-8')\n",
    "    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    corpus_chars = corpus_chars[0:10000]\n",
    "    idx_to_char = list(set(corpus_chars))\n",
    "    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "    vocab_size = len(char_to_idx)\n",
    "    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "    return corpus_indices, char_to_idx, idx_to_char, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(corpus_indices, char_to_idx, idx_to_char, vocab_size) = load_data_jay_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rnn_rlu'\n",
    "model = RNNModel('rnn_relu',vocab_size,embed_dim=100,hidden_dim=100,num_layers=2,dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_indices, batch_size, num_steps, ctx=None):\n",
    "    #相邻采样\n",
    "    corpus_indices = nd.array(corpus_indices, ctx=ctx)\n",
    "    data_len = len(corpus_indices)\n",
    "    batch_len = data_len // batch_size\n",
    "    indices = corpus_indices[0: batch_size*batch_len].reshape((\n",
    "        batch_size, batch_len))\n",
    "    epoch_size = (batch_len - 1) // num_steps\n",
    "    for i in range(epoch_size):\n",
    "        i = i * num_steps\n",
    "        X = indices[:, i: i + num_steps]\n",
    "        Y = indices[:, i + 1: i + num_steps + 1]\n",
    "        yield X, Y\n",
    "\n",
    "train_data = data_iter_consecutive(corpus_indices, 32, num_steps, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid recurrent state shape. Expecting (2, 5, 100), got (2, 2, 100).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-952061ead3c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-64c42728c910>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_data, num_epochs, num_steps, clipping_norm, pred_period)\u001b[0m\n\u001b[0;32m     79\u001b[0m                     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\Anaconda3\\envs\\mxnet\\lib\\site-packages\\mxnet\\gluon\\rnn\\rnn_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, states, sequence_length, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_RNNLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_RNNLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\Anaconda3\\envs\\mxnet\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\Anaconda3\\envs\\mxnet\\lib\\site-packages\\mxnet\\gluon\\block.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\Anaconda3\\envs\\mxnet\\lib\\site-packages\\mxnet\\gluon\\rnn\\rnn_layer.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[1;34m(self, F, inputs, states, sequence_length, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m                     raise ValueError(\n\u001b[0;32m    248\u001b[0m                         \"Invalid recurrent state shape. Expecting %s, got %s.\"%(\n\u001b[1;32m--> 249\u001b[1;33m                             str(info['shape']), str(state.shape)))\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid recurrent state shape. Expecting (2, 5, 100), got (2, 2, 100)."
     ]
    }
   ],
   "source": [
    "model.train(train_data,250,num_steps,0.2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}